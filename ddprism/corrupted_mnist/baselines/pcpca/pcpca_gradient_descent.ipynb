{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b4db45c-26ad-4d4a-af44-dde7707afe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from absl import app, flags\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from ml_collections import config_flags\n",
    "from orbax.checkpoint import CheckpointManager, CheckpointManagerOptions\n",
    "from orbax.checkpoint import PyTreeCheckpointer\n",
    "import optax\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "from ddprism import utils\n",
    "from ddprism.pcpca import pcpca_utils\n",
    "from ddprism import plotting_utils\n",
    "\n",
    "from ddprism.pcpca import pcpca_utils\n",
    "\n",
    "from ddprism.corrupted_mnist import datasets\n",
    "from ddprism.corrupted_mnist import metrics\n",
    "from ddprism.corrupted_mnist import config_base_grass, config_base_mnist\n",
    "from ddprism.corrupted_mnist import config_pcpca as config_pcpca_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa194d51-97aa-4fd7-b48e-b93d47da2d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ddprism.pcpca.pcpca_utils' from '/mnt/home/aakhmetzhanova/ddprism/ddprism/pcpca/pcpca_utils.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(pcpca_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d483f47-ce83-46a9-a931-db1874c1fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Imagenet dataset\n",
    "imagenet_path = '/mnt/home/aakhmetzhanova/ceph/galaxy-diffusion/corrupted-mnist/dataset/grass_jpeg/' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c0a2ade-0964-47b4-ac33-0839dde12954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pcpca():\n",
    "    config_pcpca = config_pcpca_.get_config() \n",
    "    \n",
    "    # Generate training datasets.\n",
    "    # Target dataset with corrupted mnist digits.\n",
    "    config_mnist = config_base_mnist.get_config()\n",
    "    rng = jax.random.key(config_mnist.rng_key)\n",
    "    rng_dataset, rng_comp, rng = jax.random.split(rng, 3)\n",
    "    \n",
    "    f_train = datasets.get_corrupted_mnist(\n",
    "        rng_dataset, grass_amp=1., mnist_amp=config_mnist.mnist_amp,\n",
    "        imagenet_path=imagenet_path,\n",
    "        dataset_size=config_mnist.dataset_size,\n",
    "        zeros_and_ones=True\n",
    "    )\n",
    "    # Target dataset with uncorrupted mnist digits for computing metrics later on.\n",
    "    f_train_uncorrupted = datasets.get_corrupted_mnist(\n",
    "        rng_dataset, grass_amp=0., mnist_amp=1.,\n",
    "        imagenet_path=imagenet_path,\n",
    "        dataset_size=config_mnist.dataset_size,\n",
    "        zeros_and_ones=True\n",
    "    )\n",
    "    # Background dataset with grass only.\n",
    "    config = config_base_grass.get_config()\n",
    "    rng = jax.random.key(config.rng_key)\n",
    "    rng_dataset, rng_comp, rng = jax.random.split(rng, 3)\n",
    "    b_train = datasets.get_corrupted_mnist(\n",
    "        rng_dataset, grass_amp=1., mnist_amp=0.,\n",
    "        imagenet_path=imagenet_path, \n",
    "        dataset_size=config.dataset_size,\n",
    "        zeros_and_ones=True)\n",
    "\n",
    "    # Generate validation datasets with corrupted mnist digits.\n",
    "    rng = jax.random.key(config_mnist.rng_key_val)\n",
    "    rng_dataset, rng_comp, rng = jax.random.split(rng, 3)\n",
    "    \n",
    "    # Validation target dataset with corrupted mnist digits.\n",
    "    f_val = datasets.get_corrupted_mnist(\n",
    "        rng_dataset, grass_amp=1., mnist_amp=config_mnist.mnist_amp,\n",
    "        imagenet_path=imagenet_path,\n",
    "        dataset_size=14720, \n",
    "        zeros_and_ones=True\n",
    "    )\n",
    "    # Take previously unseen digits for the validation set.\n",
    "    f_val_images = f_val[0][config_mnist.dataset_size:]\n",
    "    f_val_labels = f_val[1][config_mnist.dataset_size:]\n",
    "    f_val = (f_val_images, f_val_labels)\n",
    "    \n",
    "    # Validation dataset with uncorrupted mnist digits for computing metrics later on.\n",
    "    f_val_uncorrupted = datasets.get_corrupted_mnist(\n",
    "        rng_dataset, grass_amp=0., mnist_amp=1.,\n",
    "        imagenet_path=imagenet_path,\n",
    "        dataset_size=14720, \n",
    "        zeros_and_ones=True\n",
    "    )\n",
    "    # Take previously unseen digits for the validation set.\n",
    "    f_val_images = f_val_uncorrupted[0][config_mnist.dataset_size:]\n",
    "    f_val_labels = f_val_uncorrupted[1][config_mnist.dataset_size:]\n",
    "    f_val_uncorrupted = (f_val_images, f_val_labels)\n",
    "\n",
    "    config.batch_size = 128 \n",
    "    \n",
    "    # Set regularization parameter for numerical stability.\n",
    "    regularization = getattr(config, 'regularization', 1e-6)\n",
    "\n",
    "    # PCPCA analysis.\n",
    "    feat_dim = 784\n",
    "    # In PCPCA language, y_enr is enriched observation and y_bkg is background.\n",
    "    y_enr, y_enr_labels = f_train\n",
    "    y_enr = y_enr.squeeze(-1).reshape(-1, feat_dim)\n",
    "    y_bkg, y_bkg_labels = b_train\n",
    "    y_bkg = y_bkg.squeeze(-1).reshape(-1, feat_dim)\n",
    "\n",
    "    # Use batches to avoid running into memory issues\n",
    "    enr_a_mat = jnp.repeat(jnp.eye(feat_dim, feat_dim)[None, ...], config.batch_size, axis=0).copy()\n",
    "    bkg_a_mat = enr_a_mat.copy()\n",
    "\n",
    "    metrics = {}\n",
    "    # Initialize W and log_sigma using PCA of the pseudo-inverse of the\n",
    "    # observation matrix.\n",
    "    rng_w, rng = jax.random.split(rng, 2)\n",
    "    # since enr_a_mat is an identity matrix, x_pinv = y_enr\n",
    "    cov_empirical = jnp.cov(y_enr, rowvar=False)\n",
    "    u_mat, s_mat, _ = jnp.linalg.svd(cov_empirical)\n",
    "    weights_init = u_mat[:, :config_pcpca.latent_dim] * jnp.sqrt(s_mat[:config_pcpca.latent_dim])\n",
    "    weights_init += 0.01 * jax.random.normal(\n",
    "            rng_w, shape=(feat_dim, config_pcpca.latent_dim)\n",
    "        )\n",
    "\n",
    "    log_sigma_init = jnp.log(config.sigma_y)\n",
    "    mu_x_init, mu_y_init = jnp.mean(y_enr, axis=0), jnp.mean(y_bkg, axis=0), \n",
    "    params = {\n",
    "            'weights': jnp.asarray(weights_init), 'log_sigma': log_sigma_init,\n",
    "            'mu_x': mu_x_init, 'mu_y': mu_y_init\n",
    "        }\n",
    "    # Optimization loop parameters.\n",
    "    if config_pcpca.lr_schedule == 'linear':\n",
    "        schedule = optax.schedules.linear_schedule(\n",
    "            config_pcpca.learning_rate, 1e-6, config_pcpca.n_iter\n",
    "        )\n",
    "    elif config_pcpca.lr_schedule == 'cosine':\n",
    "        schedule = optax.schedules.cosine_decay_schedule(\n",
    "            init_value=config_pcpca.learning_rate, decay_steps=config_pcpca.n_iter\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f'Unknown learning rate schedule: {config_pcpca.lr_schedule}'\n",
    "        )\n",
    "\n",
    "    # Initialize Adam optimizer\n",
    "    optimizer = optax.adam(learning_rate=schedule)\n",
    "    opt_state = optimizer.init(params)\n",
    "    \n",
    "    # Run the optimization loop.\n",
    "    pbar = tqdm(range(config_pcpca.n_iter))\n",
    "    losses = []\n",
    "    for step in pbar:\n",
    "        loss_per_step = []\n",
    "        pbar_step = tqdm(range(config.dataset_size // config.batch_size))\n",
    "        for _ in pbar_step:\n",
    "            rng_enr, rng_bkg, rng = jax.random.split(rng, 3)\n",
    "            \n",
    "            batch_idx = jax.random.randint(rng_enr, shape=(config.batch_size,), minval=0, maxval=config_mnist.dataset_size)\n",
    "            y_enr_batch = y_enr[batch_idx] \n",
    "\n",
    "            batch_idx = jax.random.randint(rng_bkg, shape=(config.batch_size,), minval=0, maxval=config.dataset_size)\n",
    "            y_bkg_batch = y_bkg[batch_idx] \n",
    "    \n",
    "    \n",
    "            grad = jax.jit(pcpca_utils.loss_grad)(\n",
    "                    params, y_enr_batch, y_bkg_batch, enr_a_mat, bkg_a_mat, config_pcpca.gamma,\n",
    "                    regularization\n",
    "            )\n",
    "            loss = jax.jit(pcpca_utils.loss)(\n",
    "                    params, y_enr_batch, y_bkg_batch, enr_a_mat, bkg_a_mat, config_pcpca.gamma,\n",
    "                    regularization\n",
    "            )\n",
    "            loss_per_step.append(loss)\n",
    "            \n",
    "\n",
    "            # Update parameters\n",
    "            updates, opt_state = optimizer.update(grad, opt_state, params)\n",
    "            params = optax.apply_updates(params, updates)\n",
    "            params['log_sigma'] = jnp.log(config.sigma_y) # Fix log_sigma.\n",
    "            pbar_step.set_postfix({'loss_per_step': f'{loss:.6f}'})\n",
    "\n",
    "        # Log our loss.\n",
    "        loss_per_step = jnp.asarray(loss_per_step).mean()\n",
    "        pbar.set_postfix({'loss': f'{loss_per_step:.6f}'})\n",
    "        losses.append(loss_per_step)\n",
    "\n",
    "    print(params)\n",
    "    return params, losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1048b5c6-4267-4395-a69f-e81c93aaafbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/256 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/256 [00:49<?, ?it/s, loss_per_step=nan]\u001b[A\n",
      "  0%|          | 1/256 [00:49<3:28:55, 49.16s/it, loss_per_step=nan]\u001b[A\n",
      "  0%|          | 1/256 [01:33<3:28:55, 49.16s/it, loss_per_step=nan]\u001b[A\n",
      "  1%|          | 2/256 [02:17<4:50:25, 68.60s/it, loss_per_step=nan]\u001b[A\n",
      "  0%|          | 0/100 [02:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m params, losses \u001b[38;5;241m=\u001b[39m \u001b[43mrun_pcpca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 149\u001b[0m, in \u001b[0;36mrun_pcpca\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m batch_idx \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(rng_bkg, shape\u001b[38;5;241m=\u001b[39m(config\u001b[38;5;241m.\u001b[39mbatch_size,), minval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, maxval\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m    146\u001b[0m y_bkg_batch \u001b[38;5;241m=\u001b[39m y_bkg[batch_idx] \n\u001b[0;32m--> 149\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpcpca_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_grad\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_enr_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_bkg_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menr_a_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbkg_a_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_pcpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregularization\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m loss \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mjit(pcpca_utils\u001b[38;5;241m.\u001b[39mloss)(\n\u001b[1;32m    154\u001b[0m         params, y_enr_batch, y_bkg_batch, enr_a_mat, bkg_a_mat, config_pcpca\u001b[38;5;241m.\u001b[39mgamma,\n\u001b[1;32m    155\u001b[0m         regularization\n\u001b[1;32m    156\u001b[0m )\n\u001b[1;32m    157\u001b[0m loss_per_step\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params, losses = run_pcpca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30bfefb-2e4f-4702-95c5-de2e297d9e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-env",
   "language": "python",
   "name": "jax-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
