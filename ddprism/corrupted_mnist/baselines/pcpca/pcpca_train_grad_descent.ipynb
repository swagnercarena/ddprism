{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779b3daf-ca27-408f-a4e0-951d8627dd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 17:10:45.869894: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752873045.886248  982620 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752873045.891103  982620 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752873045.903699  982620 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752873045.903723  982620 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752873045.903724  982620 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752873045.903725  982620 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from absl import app, flags\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from ml_collections import config_flags\n",
    "from orbax.checkpoint import CheckpointManager, CheckpointManagerOptions, PyTreeCheckpointer\n",
    "import optax\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "from ddprism.corrupted_mnist import datasets\n",
    "from ddprism.metrics import metrics, image_metrics\n",
    "from ddprism.pcpca import pcpca_utils\n",
    "\n",
    "from ddprism.corrupted_mnist import config_base_grass, config_base_mnist\n",
    "import config_base_pcpca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314ef0f2-57fc-4ace-ba02-22d37c28a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to Imagenet dataset\n",
    "imagenet_path = '/mnt/home/aakhmetzhanova/ceph/galaxy-diffusion/corrupted-mnist/dataset/grass_jpeg/' \n",
    "classifier_path = Path('/mnt/home/swagner/ceph/corrupted_mnist/mnist_classifier/')\n",
    "\n",
    "@partial(jax.jit, static_argnames=['batch_size'])\n",
    "def get_loss_grad(params, x, y, gamma, regularization, batch_size=16):\n",
    "    a_mat = jnp.eye(x.shape[-1])[None, ...]\n",
    "\n",
    "    def calculate_loss_grad(data):\n",
    "        x, y = data\n",
    "        grad = pcpca_utils.loss_grad(\n",
    "            params, x[None, ...], y[None, ...], a_mat, a_mat, gamma, regularization\n",
    "        )\n",
    "        return grad\n",
    "    \n",
    "    loss_grad = jax.lax.map(calculate_loss_grad, (x, y), batch_size=batch_size)\n",
    "    return loss_grad\n",
    "        \n",
    "\n",
    "@partial(jax.jit, static_argnames=['batch_size'])\n",
    "def get_loss(params, x, y, gamma, regularization, batch_size=16):\n",
    "    a_mat = jnp.eye(x.shape[-1])\n",
    "    \n",
    "    def calculate_loss_grad(data):\n",
    "        x, y = data\n",
    "        loss = pcpca_utils.loss(\n",
    "            params, x[None, ...], y[None, ...], a_mat, a_mat, gamma, regularization\n",
    "        )\n",
    "        return loss\n",
    "        \n",
    "    loss = jax.lax.map(calculate_loss, (x, y), batch_size=batch_size)\n",
    "    return loss\n",
    "\n",
    "@partial(jax.jit, static_argnames=['batch_size', 'img_dim'])\n",
    "def get_posterior_samples(rng, params, x, y, mnist_amp, img_dim=28, batch_size=16):\n",
    "    \"\"\"Computes posterior samples for a given target dataset, given a dictionary of pcpca parameters.\n",
    "    \n",
    "    Returns:\n",
    "        Posterior samples.\n",
    "    \n",
    "    \"\"\"\n",
    "    # ...\n",
    "    a_mat = jnp.eye(x.shape[-1])\n",
    "    bkg_mean = y.mean(axis=0)\n",
    "\n",
    "    # Get individual random keys for each image.\n",
    "    rng_post = jax.random.split(rng, x.shape[0])\n",
    "    \n",
    "    def calculate_posterior(x):\n",
    "        return pcpca_utils.calculate_posterior(params, x, a_mat) \n",
    "\n",
    "    def post_samples(args):\n",
    "        rng, x = args\n",
    "        mean, sigma = calculate_posterior(x)\n",
    "        return (jax.random.multivariate_normal(rng, mean, sigma) - bkg_mean) / mnist_amp\n",
    "    \n",
    "        \n",
    "    post_samples = jax.lax.map(post_samples, (rng_post, x), batch_size=batch_size)\n",
    "    return post_samples.reshape(-1, img_dim, img_dim, 1)\n",
    "\n",
    "def get_prior_samples(rng, params, num_samples, latent_dim, feat_dim, bkg, mnist_amp, img_dim=28):\n",
    "    \"\"\"Computes posterior samples for a given target dataset, given a dictionary of pcpca parameters.\n",
    "    \n",
    "    Returns:\n",
    "        Posterior samples.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Draw latent vectors and noise vectors.\n",
    "    rng_z, rng_eps, rng = jax.random.split(rng, 3)\n",
    "    z_x = jax.random.multivariate_normal(\n",
    "        rng_z, mean=jnp.zeros((num_samples, latent_dim)), cov=jnp.eye(latent_dim)\n",
    "    )\n",
    "    \n",
    "    eps_x = jax.random.multivariate_normal(\n",
    "        rng_eps, mean=jnp.zeros((num_samples, feat_dim)), cov = jnp.exp(params['log_sigma'])**2*jnp.eye(feat_dim)\n",
    "    )\n",
    "    # Compute prior samples for target dataset.\n",
    "    prior_samples = ((params['weights'] @ z_x.T).T + params['mu'] + eps_x)\n",
    "    \n",
    "    # Subtract contribution due to the background signal and scale by the appropriate amplitude.\n",
    "    prior_samples = (prior_samples - bkg.mean(axis=0)) / mnist_amp\n",
    "    prior_samples = prior_samples.reshape(-1, img_dim, img_dim, 1)\n",
    "    \n",
    "    return prior_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e779b788-232e-407a-b301-c638e9026b22",
   "metadata": {},
   "source": [
    "# Iterate through batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9198f599-150c-4c22-8c0f-6d8fc7aeb547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pcpca(config_mnist, config_grass, config_pcpca, workdir):\n",
    "    # Generate training datasets.\n",
    "    # Target dataset with corrupted mnist digits.\n",
    "    \n",
    "    # RNG key from config.\n",
    "    rng = jax.random.key(config_mnist.rng_key)\n",
    "    \n",
    "    # Set up wandb logging and checkpointing.\n",
    "    wandb.init(\n",
    "        config=config_pcpca.copy_and_resolve_references(),\n",
    "        project=config_pcpca.wandb_kwargs.get('project', None),\n",
    "        name=config_pcpca.wandb_kwargs.get('run_name', None),\n",
    "        mode=config_pcpca.wandb_kwargs.get('mode', 'disabled')\n",
    "    )\n",
    "    \n",
    "    rng_dataset, rng_comp, rng = jax.random.split(rng, 3)\n",
    "    \n",
    "    f_train = datasets.get_corrupted_mnist(\n",
    "        rng_dataset, grass_amp=1., mnist_amp=config_mnist.mnist_amp,\n",
    "        imagenet_path=imagenet_path,\n",
    "        dataset_size=config_mnist.dataset_size,\n",
    "        zeros_and_ones=True\n",
    "    )\n",
    "    # Target dataset with uncorrupted mnist digits for computing metrics later on.\n",
    "    f_train_uncorrupted = datasets.get_corrupted_mnist(\n",
    "        rng_dataset, grass_amp=0., mnist_amp=1.,\n",
    "        imagenet_path=imagenet_path,\n",
    "        dataset_size=config_mnist.dataset_size,\n",
    "        zeros_and_ones=True\n",
    "    )\n",
    "    # Background dataset with grass only.\n",
    "    #config_grass = config_base_grass.get_config()\n",
    "    rng = jax.random.key(config_grass.rng_key)\n",
    "    rng_dataset, rng_comp, rng = jax.random.split(rng, 3)\n",
    "    b_train = datasets.get_corrupted_mnist(\n",
    "        rng_dataset, grass_amp=1., mnist_amp=0.,\n",
    "        imagenet_path=imagenet_path, \n",
    "        dataset_size=config_grass.dataset_size,\n",
    "        zeros_and_ones=True)\n",
    "\n",
    "\n",
    "    # Prepare data for PCPCA\n",
    "    x, x_labels = f_train\n",
    "    y, y_labels = b_train\n",
    "\n",
    "    feat_dim = x.shape[-3]*x.shape[-2]*x.shape[-1] \n",
    "    x = x.squeeze(-1).reshape(-1, feat_dim)\n",
    "    y = y.squeeze(-1).reshape(-1, feat_dim)\n",
    "\n",
    "    # Initialize PCPCA params close to their ML estimates.\n",
    "    weights_init = jnp.load('W_mle.npy') \n",
    "    weights_init += 1e-1*jax.random.normal(rng, shape=weights_init.shape)\n",
    "\n",
    "    mu_init = jnp.load('mu_mle.npy')\n",
    "    mu_init += 1e-1*jax.random.normal(rng, shape=mu_init.shape)\n",
    "    \n",
    "    log_sigma_init = jnp.log(config_grass.sigma_y)\n",
    "\n",
    "    # Initialize parameters.\n",
    "    params = {\n",
    "        'weights': jnp.asarray(weights_init), 'log_sigma': log_sigma_init,\n",
    "        'mu': jnp.asarray(mu_init)\n",
    "    }\n",
    "\n",
    "    # Optimization loop parameters.\n",
    "    if config_pcpca.lr_schedule == 'linear':\n",
    "        schedule = optax.schedules.linear_schedule(\n",
    "                config_pcpca.learning_rate, 1e-6, config_pcpca.n_iter\n",
    "            )\n",
    "    elif config_pcpca.lr_schedule == 'cosine':\n",
    "        schedule = optax.schedules.cosine_decay_schedule(\n",
    "                init_value=config_pcpca.learning_rate, decay_steps=config_pcpca.n_iter\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "                f'Unknown learning rate schedule: {config_pcpca.lr_schedule}'\n",
    "            )\n",
    "\n",
    "    # Initialize Adam optimizer\n",
    "    optimizer = optax.adam(learning_rate=schedule)\n",
    "    opt_state = optimizer.init(params)\n",
    "\n",
    "    # Run the optimization loop.\n",
    "    pbar = tqdm(range(config_pcpca.n_iter),)\n",
    "    \n",
    "    steps_per_epoch = x.shape[0] // config_pcpca.batch_size \n",
    "    pbar_epoch = tqdm(range(steps_per_epoch),)\n",
    "    \n",
    "    regularization = 1e-6\n",
    "    a_mat = jnp.repeat(jnp.eye(feat_dim)[None, ...], config_pcpca.batch_size, axis=0)\n",
    "    losses = []\n",
    "    for iter in pbar:\n",
    "        for step in pbar_epoch:\n",
    "            rng_epoch, rng = jax.random.split(rng, 2)\n",
    "            \n",
    "            batch_i = jax.random.randint(\n",
    "                rng_epoch, shape=(config_pcpca.batch_size,), \n",
    "                minval=0, maxval=x.shape[0]\n",
    "            )\n",
    "            \n",
    "            x_batch = x[batch_i]\n",
    "            y_batch = y[batch_i]\n",
    "\n",
    "            '''\n",
    "            # This function takes longer to run than autograd\n",
    "            grad = jax.jit(pcpca_utils.loss_grad)(\n",
    "                params, x_batch, y_batch, a_mat, a_mat, config_pcpca.gamma, regularization\n",
    "            )\n",
    "            '''\n",
    "            grad = jax.grad(pcpca_utils.loss, argnums=0, allow_int=True)(\n",
    "                params, x_batch, y_batch, a_mat, a_mat, config_pcpca.gamma, regularization\n",
    "            )\n",
    "    \n",
    "            loss = jax.jit(pcpca_utils.loss)(\n",
    "                params, x_batch, y_batch, a_mat, a_mat, config_pcpca.gamma, regularization\n",
    "            )\n",
    "            \n",
    "            \n",
    "            # Update parameters\n",
    "            updates, opt_state = optimizer.update(grad, opt_state, params)\n",
    "            params = optax.apply_updates(params, updates)\n",
    "            params['log_sigma'] = jnp.log(config_mnist.sigma_y) # Fix log_sigma.\n",
    "\n",
    "            \n",
    "            # Log our loss.\n",
    "            wandb.log(\n",
    "                {f'loss': loss},\n",
    "            )\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss:.6f}'})\n",
    "            losses.append(loss)\n",
    "    \n",
    "    # Get the posterior samples for MNIST digits.\n",
    "    rng_post, rng = jax.random.split(rng, 2)\n",
    "    post_samples  = get_posterior_samples(rng_post, params, x, y, config_mnist.mnist_amp) \n",
    "\n",
    "    # Get prior samples for MNIST digits.\n",
    "    rng_prior, rng = jax.random.split(rng, 2)\n",
    "    num_samples = x.shape[0]\n",
    "    prior_samples = get_prior_samples(rng_prior, params, num_samples, config_pcpca.latent_dim, feat_dim, y, config_mnist.mnist_amp)\n",
    "\n",
    "    # Plot the first few prior and posterior samples.\n",
    "    # Posterior samples\n",
    "    n_rows, n_cols = 3, 5\n",
    "    \n",
    "    idx = jnp.arange(10, 60, 10)\n",
    "    fig, axs = plt.subplots(n_rows, n_cols)\n",
    "    for col in range(n_cols):\n",
    "        axs[0, col].imshow(post_samples.reshape(-1, 28, 28, 1)[idx[col]], vmin=0.0, vmax=1.0)\n",
    "        axs[1, col].imshow(f_train_uncorrupted[0][idx[col]], vmin=0.0, vmax=1.0)\n",
    "        axs[2, col].imshow(f_train[0][idx[col]], vmin=0.0, vmax=1.0)\n",
    "    \n",
    "    wandb.log(\n",
    "        {f'posterior samples': wandb.Image(fig)},\n",
    "        commit=False\n",
    "    )\n",
    "\n",
    "\n",
    "    # Prior samples\n",
    "    idx = jnp.arange(10, 60, 10)\n",
    "    fig, axs = plt.subplots(1, n_cols)\n",
    "    for col in range(n_cols):\n",
    "        axs[col].imshow(prior_samples.reshape(-1, 28, 28, 1)[idx[col]], vmin=0.0, vmax=1.0)\n",
    "    \n",
    "    wandb.log(\n",
    "        {f'prior samples': wandb.Image(fig)},\n",
    "        commit=False\n",
    "    )\n",
    "\n",
    "\n",
    "    print(post_samples.shape, prior_samples.shape)\n",
    "\n",
    "    \n",
    "    # Compute and log metrics.\n",
    "    metrics_dict = {}\n",
    "    x_uncorrupted = f_train_uncorrupted[0]\n",
    "    \n",
    "    # Compute FCD on posterior and prior samples.\n",
    "    # Load classifier model to compute FCD.\n",
    "    checkpointer = PyTreeCheckpointer()\n",
    "    checkpoint_manager = CheckpointManager(classifier_path, checkpointer)\n",
    "    classifier_model = image_metrics.CNN()\n",
    "    classifier_params = checkpoint_manager.restore(checkpoint_manager.latest_step())['params'] \n",
    "    checkpoint_manager.close()\n",
    "    \n",
    "    fcd_post = image_metrics.fcd_mnist(\n",
    "        classifier_model, \n",
    "        classifier_params, \n",
    "        x_uncorrupted, \n",
    "        post_samples\n",
    "    )\n",
    "\n",
    "    wandb.log(\n",
    "            {'fcd_post': fcd_post}, commit=False\n",
    "        )\n",
    "\n",
    "    \n",
    "    fcd_prior = image_metrics.fcd_mnist(\n",
    "        classifier_model, \n",
    "        classifier_params, \n",
    "        x_uncorrupted, \n",
    "        prior_samples\n",
    "    )\n",
    "\n",
    "    wandb.log(\n",
    "            {'fcd_prior': fcd_prior}, commit=False\n",
    "        )\n",
    "\n",
    "\n",
    "    # Compute PSNR.\n",
    "    psnr_post = metrics.psnr(\n",
    "            post_samples[:config_mnist.psnr_samples],\n",
    "            x_uncorrupted[:config_mnist.psnr_samples],\n",
    "            max_spread=config_mnist.MAX_SPREAD\n",
    "    )\n",
    "    \n",
    "    wandb.log(\n",
    "            {'psnr_post': psnr_post}, commit=False\n",
    "    )\n",
    "    \n",
    "    \n",
    "    psnr_prior = metrics.psnr(\n",
    "            prior_samples[:config_mnist.psnr_samples],\n",
    "            x_uncorrupted[:config_mnist.psnr_samples],\n",
    "            max_spread=config_mnist.MAX_SPREAD\n",
    "    )\n",
    "    \n",
    "    wandb.log(\n",
    "            {'psnr_prior': psnr_prior}, commit=False\n",
    "    )\n",
    "  \n",
    "\n",
    "    # Compute PQMAss.\n",
    "    pqmass_post = metrics.pq_mass(\n",
    "        post_samples[:config_mnist.pq_mass_samples],\n",
    "        x_uncorrupted[:config_mnist.pq_mass_samples]\n",
    "    )\n",
    "    \n",
    "    wandb.log(\n",
    "            {'pqmass_post': pqmass_post}, commit=False\n",
    "    )\n",
    "    \n",
    "    pqmass_prior = metrics.pq_mass(\n",
    "        prior_samples[:config_mnist.pq_mass_samples],\n",
    "        x_uncorrupted[:config_mnist.pq_mass_samples]\n",
    "    )\n",
    "\n",
    "    wandb.log(\n",
    "            {'pqmass_prior': pqmass_prior}, commit=False\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Save parameters to a checkpoint.\n",
    "    checkpointer = PyTreeCheckpointer()\n",
    "    checkpoint_options = CheckpointManagerOptions(\n",
    "        enable_async_checkpointing=False\n",
    "    )\n",
    "    checkpoint_manager = CheckpointManager(\n",
    "        os.path.join(workdir, 'checkpoints'), checkpointer,\n",
    "        options=checkpoint_options\n",
    "    )\n",
    "    checkpoint_manager.save(0, params)\n",
    "    checkpoint_manager.close()\n",
    "    \n",
    "    # Record performance metrics (FCD, PSNR, PQMass).\n",
    "    metrics_dict['fcd_post'] = float(fcd_post)\n",
    "    metrics_dict['fcd_prior'] = float(fcd_prior)\n",
    "    \n",
    "    metrics_dict['psnr_post'] = float(psnr_post)\n",
    "    metrics_dict['psnr_prior'] = float(psnr_prior)\n",
    "    \n",
    "    metrics_dict['pqmass_post'] = float(pqmass_post)\n",
    "    metrics_dict['pqmass_prior'] = float(pqmass_prior)\n",
    "\n",
    "    wandb.finish()\n",
    "    \n",
    "    \n",
    "    return params, losses, metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583f888-3fdb-4c45-a7a6-b18b259abba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maakhmetzhanova\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/home/aakhmetzhanova/ddprism/ddprism/corrupted_mnist/baselines/pcpca/wandb/run-20250718_173622-ir0mk1v1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstoic-bee-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aakhmetzhanova/pcpca-mnist-downsample\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aakhmetzhanova/pcpca-mnist-downsample/runs/ir0mk1v1\u001b[0m\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s, loss=-224606.296875]\n",
      "  0%|          | 0/10 [00:01<?, ?it/s, loss=-329507.187500]\n",
      "  0%|          | 0/10 [00:01<?, ?it/s, loss=-89963.054688] \n",
      "  0%|          | 0/10 [00:02<?, ?it/s, loss=-110108.320312]\n",
      "  0%|          | 0/10 [00:02<?, ?it/s, loss=26200.037109]  \n",
      "  0%|          | 0/10 [00:03<?, ?it/s, loss=-169431.656250]\n",
      "  0%|          | 0/10 [00:03<?, ?it/s, loss=-384961.375000]\n",
      "  0%|          | 0/10 [00:03<?, ?it/s, loss=59965.093750]  \n",
      "  0%|          | 0/10 [00:04<?, ?it/s, loss=64287.882812]\n",
      "  0%|          | 0/10 [00:04<?, ?it/s, loss=-79369.062500]\n",
      "  0%|          | 0/10 [00:05<?, ?it/s, loss=-18629.738281]\n",
      "  0%|          | 0/10 [00:05<?, ?it/s, loss=188488.750000]\n",
      "  0%|          | 0/10 [00:05<?, ?it/s, loss=-75477.007812]\n",
      "  0%|          | 0/10 [00:06<?, ?it/s, loss=-116095.429688]\n",
      "  0%|          | 0/10 [00:06<?, ?it/s, loss=-107210.906250]\n",
      "  0%|          | 0/10 [00:07<?, ?it/s, loss=-43724.941406] \n",
      "  0%|          | 0/10 [00:07<?, ?it/s, loss=-117593.546875]\n",
      "  0%|          | 0/10 [00:08<?, ?it/s, loss=-37664.070312] \n",
      "  0%|          | 0/10 [00:08<?, ?it/s, loss=-38616.613281]\n",
      "  0%|          | 0/10 [00:08<?, ?it/s, loss=-177764.250000]\n",
      "  0%|          | 0/10 [00:09<?, ?it/s, loss=-65981.062500] \n",
      "  0%|          | 0/10 [00:09<?, ?it/s, loss=-255379.265625]\n",
      "  0%|          | 0/10 [00:10<?, ?it/s, loss=-142906.734375]\n",
      "  0%|          | 0/10 [00:10<?, ?it/s, loss=-169456.062500]\n",
      "  0%|          | 0/10 [00:10<?, ?it/s, loss=-106703.257812]\n",
      "  0%|          | 0/10 [00:11<?, ?it/s, loss=-394509.718750]\n",
      "  0%|          | 0/10 [00:11<?, ?it/s, loss=-91234.093750] \n",
      "  0%|          | 0/10 [00:12<?, ?it/s, loss=-53482.140625]\n",
      "  0%|          | 0/10 [00:12<?, ?it/s, loss=49136.941406] \n",
      "  0%|          | 0/10 [00:12<?, ?it/s, loss=-240413.218750]\n",
      "  0%|          | 0/10 [00:13<?, ?it/s, loss=-41257.554688] \n",
      "  0%|          | 0/10 [00:13<?, ?it/s, loss=-87302.273438]\n",
      "  0%|          | 0/10 [00:14<?, ?it/s, loss=-66170.523438]\n",
      "  0%|          | 0/10 [00:14<?, ?it/s, loss=-1199993.750000]\n",
      "  0%|          | 0/10 [00:15<?, ?it/s, loss=-89254.476562]  \n",
      "  0%|          | 0/10 [00:15<?, ?it/s, loss=-272526.750000]\n",
      "  0%|          | 0/10 [00:15<?, ?it/s, loss=-141239.875000]\n",
      "  0%|          | 0/10 [00:16<?, ?it/s, loss=115668.250000] \n",
      "  0%|          | 0/10 [00:16<?, ?it/s, loss=277842.593750]\n",
      "  0%|          | 0/10 [00:17<?, ?it/s, loss=120534.390625]\n",
      "  0%|          | 0/10 [00:17<?, ?it/s, loss=-159290.437500]\n",
      "  0%|          | 0/10 [00:17<?, ?it/s, loss=51175.187500]  \n",
      "  0%|          | 0/10 [00:18<?, ?it/s, loss=13105.246094]\n",
      "  0%|          | 0/10 [00:18<?, ?it/s, loss=-295395.125000]\n",
      "  0%|          | 0/10 [00:19<?, ?it/s, loss=-44550.234375] \n",
      "  0%|          | 0/10 [00:19<?, ?it/s, loss=711099.625000]\n",
      "  0%|          | 0/10 [00:20<?, ?it/s, loss=-94716.656250]\n",
      "  0%|          | 0/10 [00:20<?, ?it/s, loss=-69044.929688]\n",
      "  0%|          | 0/10 [00:20<?, ?it/s, loss=-129514.437500]\n",
      "  0%|          | 0/10 [00:21<?, ?it/s, loss=-105248.718750]\n",
      "  0%|          | 0/10 [00:21<?, ?it/s, loss=-35057.898438] \n",
      "  0%|          | 0/10 [00:22<?, ?it/s, loss=-580276.125000]\n",
      "  0%|          | 0/10 [00:22<?, ?it/s, loss=-136224.000000]\n",
      "  0%|          | 0/10 [00:22<?, ?it/s, loss=-15918.571289] \n",
      "  0%|          | 0/10 [00:23<?, ?it/s, loss=-123225.773438]\n",
      "  0%|          | 0/10 [00:23<?, ?it/s, loss=-245290.906250]\n",
      "  0%|          | 0/10 [00:24<?, ?it/s, loss=227935.156250] \n",
      "  0%|          | 0/10 [00:24<?, ?it/s, loss=105295.085938]\n",
      "  0%|          | 0/10 [00:24<?, ?it/s, loss=99581.812500] \n",
      "  0%|          | 0/10 [00:25<?, ?it/s, loss=152746.937500]\n",
      "  0%|          | 0/10 [00:25<?, ?it/s, loss=3181317.500000]\n",
      "  0%|          | 0/10 [00:26<?, ?it/s, loss=278822.125000] \n",
      "  0%|          | 0/10 [00:26<?, ?it/s, loss=-1091757.625000]\n",
      "  0%|          | 0/10 [00:27<?, ?it/s, loss=-704393.562500] \n",
      "  0%|          | 0/10 [00:27<?, ?it/s, loss=-615662.875000]\n",
      "  0%|          | 0/10 [00:27<?, ?it/s, loss=-113052.171875]\n",
      "  0%|          | 0/10 [00:28<?, ?it/s, loss=-47340.406250] \n",
      "  0%|          | 0/10 [00:28<?, ?it/s, loss=-122171.953125]\n",
      "  0%|          | 0/10 [00:29<?, ?it/s, loss=390637.812500] \n",
      "  0%|          | 0/10 [00:29<?, ?it/s, loss=-243098.265625]\n",
      "  0%|          | 0/10 [00:29<?, ?it/s, loss=-153052.781250]\n",
      "  0%|          | 0/10 [00:30<?, ?it/s, loss=-50117.796875] \n",
      "  0%|          | 0/10 [00:30<?, ?it/s, loss=-161897.906250]\n",
      "  0%|          | 0/10 [00:31<?, ?it/s, loss=-45840.539062] \n",
      "  0%|          | 0/10 [00:31<?, ?it/s, loss=-63086.636719]\n",
      "  0%|          | 0/10 [00:32<?, ?it/s, loss=-165932.281250]\n",
      "  0%|          | 0/10 [00:32<?, ?it/s, loss=29372.244141]  \n",
      "  0%|          | 0/10 [00:32<?, ?it/s, loss=-44177.878906]\n",
      "  0%|          | 0/10 [00:33<?, ?it/s, loss=-150290.281250]\n",
      "  0%|          | 0/10 [00:33<?, ?it/s, loss=571582.562500] \n",
      "  0%|          | 0/10 [00:34<?, ?it/s, loss=-23444.583984]\n",
      "  0%|          | 0/10 [00:34<?, ?it/s, loss=-30280.220703]\n",
      "  0%|          | 0/10 [00:34<?, ?it/s, loss=-7355.622070] \n",
      "  0%|          | 0/10 [00:35<?, ?it/s, loss=-343118.687500]\n",
      "  0%|          | 0/10 [00:35<?, ?it/s, loss=-102647.062500]\n",
      "  0%|          | 0/10 [00:36<?, ?it/s, loss=-238749.781250]\n",
      "  0%|          | 0/10 [00:36<?, ?it/s, loss=-127903.195312]\n",
      "  0%|          | 0/10 [00:36<?, ?it/s, loss=-221885.812500]\n",
      "  0%|          | 0/10 [00:37<?, ?it/s, loss=-364619.000000]\n",
      "  0%|          | 0/10 [00:37<?, ?it/s, loss=783818.250000] \n",
      "  0%|          | 0/10 [00:38<?, ?it/s, loss=-217122.406250]\n",
      "  0%|          | 0/10 [00:38<?, ?it/s, loss=117806.171875] \n",
      "  0%|          | 0/10 [00:39<?, ?it/s, loss=-100167.937500]\n",
      "  0%|          | 0/10 [00:39<?, ?it/s, loss=-41286.921875] \n",
      "  0%|          | 0/10 [00:39<?, ?it/s, loss=-43237.429688]\n",
      "  0%|          | 0/10 [00:40<?, ?it/s, loss=-70772.960938]\n",
      "  0%|          | 0/10 [00:40<?, ?it/s, loss=670081.000000]\n",
      "  0%|          | 0/10 [00:41<?, ?it/s, loss=-51230.250000]\n",
      "  0%|          | 0/10 [00:41<?, ?it/s, loss=-122309.812500]\n",
      "  0%|          | 0/10 [00:41<?, ?it/s, loss=-146677.671875]\n",
      "  0%|          | 0/10 [00:42<?, ?it/s, loss=-124252.546875]\n",
      "  0%|          | 0/10 [00:42<?, ?it/s, loss=-35126.320312] \n",
      "  0%|          | 0/10 [00:43<?, ?it/s, loss=165176.062500]\n",
      "  0%|          | 0/10 [00:43<?, ?it/s, loss=198461.750000]\n",
      "  0%|          | 0/10 [00:44<?, ?it/s, loss=-306269.468750]\n",
      "  0%|          | 0/10 [00:44<?, ?it/s, loss=-333975.656250]\n",
      "  0%|          | 0/10 [00:44<?, ?it/s, loss=-98985.125000] \n",
      "  0%|          | 0/10 [00:45<?, ?it/s, loss=160238.859375]\n",
      "  0%|          | 0/10 [00:45<?, ?it/s, loss=-271533.500000]\n",
      "  0%|          | 0/10 [00:46<?, ?it/s, loss=-157343.859375]\n",
      "  0%|          | 0/10 [00:46<?, ?it/s, loss=-506021.625000]\n",
      "  0%|          | 0/10 [00:46<?, ?it/s, loss=1533890.625000]\n",
      "  0%|          | 0/10 [00:47<?, ?it/s, loss=-164148.906250]\n",
      "  0%|          | 0/10 [00:47<?, ?it/s, loss=-3156183.500000]\n",
      "  0%|          | 0/10 [00:48<?, ?it/s, loss=7952780.000000] \n",
      "  0%|          | 0/10 [00:48<?, ?it/s, loss=-2703610.250000]\n",
      "  0%|          | 0/10 [00:49<?, ?it/s, loss=-72422.039062]  \n",
      "  0%|          | 0/10 [00:49<?, ?it/s, loss=-28411.697266]\n",
      "  0%|          | 0/10 [00:49<?, ?it/s, loss=-2306560.250000]\n",
      "  0%|          | 0/10 [00:50<?, ?it/s, loss=-89237.367188]  \n",
      "  0%|          | 0/10 [00:50<?, ?it/s, loss=-416445.125000]\n",
      "  0%|          | 0/10 [00:51<?, ?it/s, loss=-1008306.687500]\n",
      "  0%|          | 0/10 [00:51<?, ?it/s, loss=94278.562500]   \n",
      "  0%|          | 0/10 [00:51<?, ?it/s, loss=322608.656250]\n",
      "  0%|          | 0/10 [00:52<?, ?it/s, loss=-5341371.000000]\n",
      "  0%|          | 0/10 [00:52<?, ?it/s, loss=3714880.250000] \n",
      "  0%|          | 0/10 [00:53<?, ?it/s, loss=-158134.015625]\n",
      "  0%|          | 0/10 [00:53<?, ?it/s, loss=-133561.234375]\n",
      "  0%|          | 0/10 [00:53<?, ?it/s, loss=-134633.281250]\n",
      "  0%|          | 0/10 [00:54<?, ?it/s, loss=-44097.492188] \n",
      "  0%|          | 0/10 [00:54<?, ?it/s, loss=-76175.937500]\n",
      "  0%|          | 0/10 [00:55<?, ?it/s, loss=45356.171875] \n",
      "  0%|          | 0/10 [00:55<?, ?it/s, loss=-226051.703125]\n",
      "  0%|          | 0/10 [00:56<?, ?it/s, loss=-16983.808594] \n",
      "  0%|          | 0/10 [00:56<?, ?it/s, loss=-327052.531250]\n",
      "  0%|          | 0/10 [00:56<?, ?it/s, loss=321686.562500] \n",
      "  0%|          | 0/10 [00:57<?, ?it/s, loss=-118675.187500]\n",
      "  0%|          | 0/10 [00:57<?, ?it/s, loss=-177873.250000]\n",
      "  0%|          | 0/10 [00:58<?, ?it/s, loss=-187632.796875]\n",
      "  0%|          | 0/10 [00:58<?, ?it/s, loss=7682.730469]   \n",
      "  0%|          | 0/10 [00:58<?, ?it/s, loss=154279.781250]\n",
      "  0%|          | 0/10 [00:59<?, ?it/s, loss=36601.582031] \n",
      "  0%|          | 0/10 [00:59<?, ?it/s, loss=-112776.640625]\n",
      "  0%|          | 0/10 [01:00<?, ?it/s, loss=-69600.078125] \n",
      "  0%|          | 0/10 [01:00<?, ?it/s, loss=228825.343750]\n",
      "  0%|          | 0/10 [01:01<?, ?it/s, loss=2575995.500000]\n",
      "  0%|          | 0/10 [01:01<?, ?it/s, loss=-433836.968750]\n",
      "  0%|          | 0/10 [01:01<?, ?it/s, loss=-470580.562500]\n",
      "  0%|          | 0/10 [01:02<?, ?it/s, loss=-53773.156250] \n",
      "  0%|          | 0/10 [01:02<?, ?it/s, loss=-71829.851562]\n",
      "  0%|          | 0/10 [01:03<?, ?it/s, loss=-25037.898438]\n",
      "  0%|          | 0/10 [01:03<?, ?it/s, loss=-255030.625000]\n",
      "  0%|          | 0/10 [01:03<?, ?it/s, loss=-276408.062500]\n",
      "  0%|          | 0/10 [01:04<?, ?it/s, loss=-486385.937500]\n",
      "  0%|          | 0/10 [01:04<?, ?it/s, loss=-366250.062500]\n",
      "  0%|          | 0/10 [01:05<?, ?it/s, loss=-17977.212891] \n",
      "  0%|          | 0/10 [01:05<?, ?it/s, loss=442835.687500]\n",
      "  0%|          | 0/10 [01:05<?, ?it/s, loss=-97682.195312]\n",
      "  0%|          | 0/10 [01:06<?, ?it/s, loss=-157522.265625]\n",
      "  0%|          | 0/10 [01:06<?, ?it/s, loss=-22491.927734] \n",
      "  0%|          | 0/10 [01:07<?, ?it/s, loss=117546.914062]\n",
      "  0%|          | 0/10 [01:07<?, ?it/s, loss=-277658.062500]\n",
      "  0%|          | 0/10 [01:08<?, ?it/s, loss=92360.875000]  \n",
      "  0%|          | 0/10 [01:08<?, ?it/s, loss=285310.437500]\n",
      "  0%|          | 0/10 [01:08<?, ?it/s, loss=-315375.375000]\n",
      "  0%|          | 0/10 [01:09<?, ?it/s, loss=-274008.500000]\n",
      "  0%|          | 0/10 [01:09<?, ?it/s, loss=-140210.609375]\n",
      "  0%|          | 0/10 [01:10<?, ?it/s, loss=-139239.343750]\n",
      "  0%|          | 0/10 [01:10<?, ?it/s, loss=-125958.148438]\n",
      "  0%|          | 0/10 [01:10<?, ?it/s, loss=-124121.734375]\n",
      "  0%|          | 0/10 [01:11<?, ?it/s, loss=-118815.914062]\n",
      "  0%|          | 0/10 [01:11<?, ?it/s, loss=-118283.437500]\n",
      "  0%|          | 0/10 [01:12<?, ?it/s, loss=-74638.968750] \n",
      "  0%|          | 0/10 [01:12<?, ?it/s, loss=-86748.804688]\n",
      "  0%|          | 0/10 [01:13<?, ?it/s, loss=-80464.953125]\n",
      "  0%|          | 0/10 [01:13<?, ?it/s, loss=-82209.617188]\n",
      "  0%|          | 0/10 [01:13<?, ?it/s, loss=-87406.250000]\n",
      "  0%|          | 0/10 [01:14<?, ?it/s, loss=-59415.746094]\n",
      "  0%|          | 0/10 [01:14<?, ?it/s, loss=-82392.750000]\n",
      "  0%|          | 0/10 [01:15<?, ?it/s, loss=-88612.523438]\n",
      "  0%|          | 0/10 [01:15<?, ?it/s, loss=-101241.500000]\n",
      "  0%|          | 0/10 [01:15<?, ?it/s, loss=-73406.906250] \n",
      "  0%|          | 0/10 [01:16<?, ?it/s, loss=-84226.476562]\n",
      "  0%|          | 0/10 [01:16<?, ?it/s, loss=-88080.132812]\n",
      "  0%|          | 0/10 [01:17<?, ?it/s, loss=1349401.250000]\n",
      "  0%|          | 0/10 [01:17<?, ?it/s, loss=-84460.226562] \n",
      "  0%|          | 0/10 [01:17<?, ?it/s, loss=-4212.076660] \n",
      "  0%|          | 0/10 [01:18<?, ?it/s, loss=-2486578.000000]\n",
      "  0%|          | 0/10 [01:18<?, ?it/s, loss=388432.906250]  \n",
      "  0%|          | 0/10 [01:19<?, ?it/s, loss=86855.968750] \n",
      "  0%|          | 0/10 [01:19<?, ?it/s, loss=601953.125000]\n",
      "  0%|          | 0/10 [01:20<?, ?it/s, loss=-91204.687500]\n",
      "  0%|          | 0/10 [01:20<?, ?it/s, loss=112.073730]   \n",
      "  0%|          | 0/10 [01:21<?, ?it/s, loss=-323003.062500]\n",
      "  0%|          | 0/10 [01:21<?, ?it/s, loss=252239.859375] \n",
      "  0%|          | 0/10 [01:21<?, ?it/s, loss=132393.859375]\n",
      "  0%|          | 0/10 [01:22<?, ?it/s, loss=-145810.796875]\n",
      "  0%|          | 0/10 [01:22<?, ?it/s, loss=-999020.000000]\n",
      "  0%|          | 0/10 [01:23<?, ?it/s, loss=-399427.906250]\n",
      "  0%|          | 0/10 [01:23<?, ?it/s, loss=-140030.203125]\n",
      "  0%|          | 0/10 [01:24<?, ?it/s, loss=-343803.750000]\n",
      "  0%|          | 0/10 [01:24<?, ?it/s, loss=-231504.468750]\n",
      "  0%|          | 0/10 [01:24<?, ?it/s, loss=-143191.031250]\n",
      "  0%|          | 0/10 [01:25<?, ?it/s, loss=-178871.140625]\n",
      "  0%|          | 0/10 [01:25<?, ?it/s, loss=-236570.843750]\n",
      "  0%|          | 0/10 [01:26<?, ?it/s, loss=-261180.140625]\n",
      "  0%|          | 0/10 [01:26<?, ?it/s, loss=-318251.156250]\n",
      "  0%|          | 0/10 [01:26<?, ?it/s, loss=172675.234375] \n",
      "  0%|          | 0/10 [01:27<?, ?it/s, loss=223658.531250]\n",
      "  0%|          | 0/10 [01:27<?, ?it/s, loss=189085.843750]\n",
      "  0%|          | 0/10 [01:28<?, ?it/s, loss=211193.921875]\n",
      "  0%|          | 0/10 [01:28<?, ?it/s, loss=49451.812500] \n",
      "  0%|          | 0/10 [01:29<?, ?it/s, loss=11528.824219]\n",
      "  0%|          | 0/10 [01:29<?, ?it/s, loss=29995.792969]\n",
      "  0%|          | 0/10 [01:29<?, ?it/s, loss=110029.812500]\n",
      "  0%|          | 0/10 [01:30<?, ?it/s, loss=-1154442.500000]\n",
      "100%|██████████| 216/216 [01:30<00:00,  2.39it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [14:42<01:29, 89.29s/it, loss=-80829.500000]  "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(pcpca_utils)\n",
    "\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "workdir = '/mnt/home/aakhmetzhanova/ceph/pcpca_mnist/'\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "\n",
    "config_pcpca = config_base_pcpca.get_config()\n",
    "\n",
    "config_mnist = config_pcpca.config_mnist\n",
    "config_grass = config_pcpca.config_grass\n",
    "\n",
    "config_pcpca.lr_schedule = 'linear'\n",
    "config_pcpca.learning_rate = 1e-6\n",
    "config_pcpca.n_iter = 10\n",
    "\n",
    "config_pcpca.batch_size = 64\n",
    "\n",
    "config_pcpca.wandb_kwargs = ConfigDict(\n",
    "        {\n",
    "            'project': 'pcpca-mnist-downsample', 'mode': 'online',\n",
    "            'run_name': None\n",
    "        }\n",
    "    )\n",
    "\n",
    "params, losses, metrics_dict = run_pcpca(config_mnist, config_grass, config_pcpca, workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0e40d53-be54-4f52-beec-1de1958fab13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15554856fe20>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6529ac75-ab9f-4a07-89b5-d20a73225d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9f0c00-ac0b-4fee-b087-f89f6244859c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a34737-3556-42ea-9926-3a516673dc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-env",
   "language": "python",
   "name": "jax-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
